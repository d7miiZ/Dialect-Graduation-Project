{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from pickle import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer, EarlyStoppingCallback, BatchEncoding\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "import optuna\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"models/finalized_models/2021-09-30-train-0.8921535648994515\",output_hidden_states=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.1698e-01,  2.8024e-02, -7.8250e-01, -4.1261e-01, -2.0064e+00,\n",
       "        -1.8946e+00,  6.1162e-02,  3.5752e-01, -9.4477e-01,  4.2975e-01,\n",
       "        -2.6864e+00,  7.0915e-01, -5.5534e-01,  6.2803e-01, -2.3906e+00,\n",
       "         7.3605e-01, -6.6854e-01, -7.3385e-01,  4.4926e-01, -8.7689e-01,\n",
       "         3.2938e-02, -1.2178e-01,  1.6147e+00,  1.5512e+00, -2.1013e-01,\n",
       "        -2.1563e+00,  7.0385e-01, -1.3519e+00,  2.0527e+00, -1.3488e+00,\n",
       "         9.2105e-01, -1.4275e+00, -7.1441e-01, -8.2480e-01,  2.1275e-01,\n",
       "        -1.1187e+00,  1.0586e+00, -5.6239e-01,  1.3157e+00, -6.0936e-01,\n",
       "         5.2843e-01, -1.0474e+00,  1.4777e-01, -4.1643e-01, -6.2539e-01,\n",
       "        -1.3893e+00,  4.1672e+00,  8.2867e-01, -4.6922e-01, -7.5671e-01,\n",
       "         9.8978e-01, -1.1431e-01, -2.8773e-01, -1.1870e+00, -2.1438e+00,\n",
       "        -1.3279e+00, -2.2794e+00, -3.0283e-02,  3.1005e-01,  1.5610e+00,\n",
       "        -5.0476e-01,  8.8375e-02,  1.2676e+00,  5.8302e-01, -6.5239e-01,\n",
       "         4.2560e+00,  5.1048e-01,  3.7323e-01, -1.6036e+00, -6.5094e-01,\n",
       "         1.4715e+00, -1.1698e+00, -1.3660e+00, -1.6017e-01, -1.4562e-02,\n",
       "        -9.4000e-01, -7.5334e-01,  1.1083e+00, -2.4150e+00,  4.5670e+00,\n",
       "        -1.1470e+00,  1.9204e-01,  7.8609e-01,  1.0059e+00, -9.1184e-01,\n",
       "         6.0195e-02, -6.4322e-01,  4.9512e-01,  3.0180e+00,  1.7257e+00,\n",
       "        -2.8633e+00, -3.4041e+00, -1.9926e+00,  1.4883e+00,  4.2159e-01,\n",
       "        -9.7726e-01,  1.3524e+00,  4.5205e-01,  6.8893e-01, -5.3948e-02,\n",
       "        -7.0905e-01, -1.1381e+00, -2.2779e+00,  1.2684e+00,  3.3389e-01,\n",
       "        -2.6760e+00, -1.5409e+00,  3.8454e+00,  3.8592e-02, -3.1657e-01,\n",
       "         1.2419e+00,  9.2670e-01,  4.7945e-01, -2.6048e-01,  1.2818e+00,\n",
       "        -7.1748e-01, -8.5122e-01, -2.2749e+00,  1.5901e-01, -9.9435e-02,\n",
       "         2.8944e-01,  4.5715e-01, -3.6253e-01,  2.8131e-01, -4.4359e-01,\n",
       "        -1.0550e+00,  1.0682e-01,  5.2234e-01, -5.2538e+00,  2.8328e-01,\n",
       "        -1.2042e+00, -1.6657e-01,  1.8756e-01,  5.5170e-01, -3.9305e-01,\n",
       "        -4.3895e-01,  7.1349e-01, -8.1491e-02,  2.2218e-01,  2.8569e+00,\n",
       "        -2.4264e-02, -4.2366e-01, -4.5237e-01, -6.0823e-01,  6.0384e-01,\n",
       "         3.3183e-01, -1.4869e+00, -5.8264e-01,  1.0324e+00,  1.2978e+00,\n",
       "        -1.5692e+00, -2.6215e-01,  3.2408e+00,  3.6428e-01,  3.1046e-02,\n",
       "         1.2727e+00,  4.2323e-01, -3.0410e-01, -3.5290e-01,  7.6044e-02,\n",
       "         3.1599e-01,  7.8162e-01,  8.8336e-03, -2.3327e-01, -7.7709e-01,\n",
       "        -2.2097e-01,  1.3129e+00,  3.8073e-01,  1.4391e+00, -4.4280e-01,\n",
       "        -8.9955e-03, -1.7914e-01, -1.2671e+00, -7.1573e-01, -5.4801e-01,\n",
       "        -2.3972e+00,  4.5641e-01,  1.2170e+00, -8.0797e-02, -1.4581e+00,\n",
       "         4.0980e-01,  7.6294e-01, -3.6140e+00, -1.6221e+00,  2.1202e+00,\n",
       "        -4.7581e+00, -1.2277e+00, -4.3731e-01, -1.7309e+00, -4.9793e-02,\n",
       "         7.8294e-01,  3.9334e-01,  2.6989e+00, -1.4293e+00, -3.5907e-01,\n",
       "        -5.8176e-02,  2.0210e+00, -6.2183e-01, -4.6616e-01,  1.1103e+00,\n",
       "        -1.2641e+00,  5.5552e-01,  2.6616e-01,  1.2348e-01,  1.7383e+00,\n",
       "         8.8976e-01,  6.8468e+00, -1.0207e-01,  2.7575e-01,  4.1787e-01,\n",
       "         6.0997e-01, -1.4723e+00,  1.1445e+00,  1.7490e-01,  9.4471e-01,\n",
       "        -1.1880e+00, -1.5166e+00, -9.4614e-02,  8.2737e-02,  2.1440e+00,\n",
       "         1.6675e-01,  1.0502e-01, -7.1443e-01,  1.3216e+00,  1.4072e-01,\n",
       "        -5.4437e-01,  1.0446e+00,  2.9765e-01, -1.1460e-01, -2.5573e-01,\n",
       "         5.6932e-02,  1.4895e+00, -1.5695e+00,  7.5006e-01,  3.6011e+00,\n",
       "         1.0117e+00, -2.2933e-01,  2.3864e-01, -2.6715e+00, -1.3060e+00,\n",
       "        -1.7455e+00, -3.7207e+00, -1.0333e+00, -1.2370e-02, -1.5059e+00,\n",
       "         4.4023e-01,  2.3701e-01,  2.9649e+00, -7.3571e-01,  1.9490e+00,\n",
       "         3.9870e+00,  3.1080e-01, -1.1851e-01, -1.2420e+00,  6.9929e-02,\n",
       "         6.6166e-01, -9.9020e-01, -1.8397e+00,  3.5606e-01, -1.3635e-01,\n",
       "         3.3030e-01,  4.0542e-01, -1.6599e-01,  3.6629e-01, -1.7842e-01,\n",
       "         9.1097e-01,  1.5308e-01, -1.7454e+00, -1.9353e+00,  4.2225e-01,\n",
       "        -5.1648e-01,  2.0128e+00, -8.6020e-01, -7.5656e-01,  2.0097e+00,\n",
       "        -5.8933e-01,  1.5475e+00, -9.6081e-01,  5.3237e-01, -1.1033e-01,\n",
       "        -1.8536e-01, -3.2022e-01,  1.9183e+00,  2.4520e-01,  1.3146e-01,\n",
       "         9.7104e-01,  1.6895e-02,  7.8405e-02, -1.8443e+00,  1.1726e-01,\n",
       "        -1.2642e+00,  1.2522e+00, -6.4310e+00, -2.9961e-01, -1.5207e-01,\n",
       "         3.7147e-01, -2.7008e-01,  9.2209e-01,  4.7360e-01,  1.3943e+00,\n",
       "        -1.9591e-01,  1.5171e+00, -2.1384e+00,  1.0011e+00, -4.1147e-01,\n",
       "         2.0740e-01,  1.2638e+00,  2.4199e-01, -7.1237e-01, -1.6422e+00,\n",
       "        -6.4933e-01,  2.8058e+00, -1.9202e-01,  9.1645e-01, -7.6527e-02,\n",
       "        -4.8690e-01, -5.4458e-02,  3.1910e-02,  4.5349e+00, -1.7727e+00,\n",
       "        -1.1086e-01,  4.8932e-01, -3.4102e-01, -1.7996e-01,  2.8394e-01,\n",
       "        -3.4862e-01,  1.4262e+00, -3.3521e-01,  5.1695e+00,  8.4114e-01,\n",
       "        -1.4742e+00,  9.0757e-02, -1.3723e+00,  5.8017e-01,  3.0661e-01,\n",
       "         8.1005e-02, -6.9405e-01,  4.9731e-02, -2.5091e+00, -1.1014e+00,\n",
       "        -6.9062e-01,  6.2025e-01, -4.8035e-02,  1.6859e+00,  2.1552e+00,\n",
       "         1.9567e-01, -5.6347e-01,  1.5394e-01, -1.3916e-01, -1.5271e+00,\n",
       "         9.0251e-02,  4.3891e-01,  3.3014e+00,  3.9828e-01,  1.3934e-01,\n",
       "         8.4057e-01, -5.4293e+00, -9.7869e-01, -6.5449e-01, -1.0310e+00,\n",
       "         3.1838e-01, -1.2008e-01,  1.3568e-01, -4.7247e-02,  2.6897e-01,\n",
       "         2.2546e-01,  6.6782e+00,  2.3251e-01,  9.4161e-01,  1.4025e-01,\n",
       "        -8.0686e-01,  4.2123e-01, -1.6134e-01, -6.3471e-02, -3.7528e-01,\n",
       "        -2.7056e-01,  8.4690e-01,  7.8773e-01,  6.8834e-01,  1.3834e+00,\n",
       "        -8.0193e-01, -1.2794e+00,  3.2853e+00,  2.6300e-01,  1.8369e+00,\n",
       "         8.2750e-01, -2.2371e+00, -1.5355e+00, -2.1132e+00,  2.3532e+00,\n",
       "         4.1002e-01, -1.4629e-01,  3.3361e+00,  8.8001e-01, -1.6008e+00,\n",
       "        -9.3733e-01,  6.1785e-01,  4.3926e-01,  1.9586e+00, -2.4447e-02,\n",
       "        -3.8072e+00,  5.5920e+00,  1.7260e+00, -9.2504e-01, -6.4929e-01,\n",
       "         1.0470e+00,  8.7732e-01,  2.9341e+00, -1.6110e+00, -1.2825e-01,\n",
       "        -4.0743e+00, -6.8946e-01, -3.8442e-01, -2.7114e-02, -5.3157e-01,\n",
       "         2.2320e-01, -1.9142e+00, -1.0163e+00, -1.6258e-01,  6.1667e-01,\n",
       "        -9.8430e-01,  1.6800e-01, -1.2010e-01,  3.5661e-01, -3.3140e-01,\n",
       "         4.6244e-01, -1.1901e+00,  1.0892e+00, -8.9300e-01,  6.0353e-01,\n",
       "        -4.5981e-01, -3.7213e-01,  6.6794e+00,  7.6630e-01, -1.2102e+00,\n",
       "        -3.8843e-01,  1.1851e-01, -6.3307e+00,  1.7520e-01, -3.0466e+00,\n",
       "        -2.5231e-01, -1.0299e+00,  6.2278e-01, -2.1296e+00, -3.2222e-01,\n",
       "        -1.2745e+00, -3.6075e-01, -2.4688e+00,  2.1650e-01,  4.6468e-01,\n",
       "        -1.1413e+00, -5.1325e-01, -5.2492e-01,  3.5640e+00,  1.0728e-02,\n",
       "         1.1281e+00,  3.5647e-01, -9.5782e-01, -1.7197e-01,  1.1607e+00,\n",
       "         7.9484e-01,  1.2215e+00, -1.4508e+00, -9.3653e-01,  1.2289e+00,\n",
       "         3.7528e-01, -6.4559e-01,  8.1409e-01,  1.5673e+00, -2.0810e+00,\n",
       "        -1.1836e+00, -7.7707e-01,  8.0726e-02,  5.8227e-01, -5.9181e-01,\n",
       "         7.4162e-03,  1.2460e+00,  3.1673e-01,  1.4131e+00, -9.6767e-02,\n",
       "        -1.5495e-02, -1.4679e+00, -1.3133e-01,  8.2131e-01, -1.5474e+00,\n",
       "        -5.2460e-01,  5.7200e-01, -1.1007e+00,  1.0504e+01,  4.7385e-01,\n",
       "        -1.7066e+00, -4.8273e+00, -1.5077e+00, -6.0155e-01,  5.0297e-01,\n",
       "         7.5489e-01,  2.8981e+00, -2.9691e-01,  1.9623e-01, -3.5706e-02,\n",
       "        -1.4799e-01, -5.9792e-02,  7.4420e-01,  6.5056e-01,  1.7230e+00,\n",
       "         3.6890e-01, -4.5821e-01, -3.6652e-01, -6.3600e-01, -7.2704e-01,\n",
       "        -2.4519e+00, -7.2245e-01,  5.5924e-01,  2.0599e+00,  4.3751e-01,\n",
       "        -1.4589e-01, -1.0052e+00,  8.9236e-02, -5.3429e-01, -3.1754e-01,\n",
       "         8.5966e-01, -1.2704e-01, -6.8703e-01, -2.7539e+00, -6.7281e-01,\n",
       "         3.1214e+00,  1.4016e+00, -3.4295e-01,  5.8755e-01,  2.6798e-01,\n",
       "        -1.4802e-01,  7.2139e-01, -3.3451e+00,  1.2881e+00,  3.6540e-02,\n",
       "         2.0777e-01,  5.5582e-01, -1.4185e+00,  3.6362e+00,  1.2883e+00,\n",
       "         1.8179e-01, -8.4463e-01, -1.3581e+00, -1.7430e+00, -9.5862e-01,\n",
       "        -1.4996e-02,  6.5835e-01, -2.8576e+00, -1.0908e+00,  4.2468e-01,\n",
       "         2.3153e+00,  4.1949e-02,  2.2653e-01,  1.4867e+00, -5.4065e-01,\n",
       "        -1.6420e+00,  9.3826e-01,  2.3510e-01,  4.7216e-01,  1.7745e-01,\n",
       "         1.0022e+00,  4.3734e-01, -2.2021e+00,  7.5819e-02, -2.3993e+00,\n",
       "        -8.1612e-01,  1.3471e+00,  5.6017e-02,  7.7741e-01, -4.7504e-01,\n",
       "        -6.5251e-01,  4.4851e+00,  5.6713e-02, -7.8325e-01,  1.4348e+00,\n",
       "        -1.3377e+00, -1.8560e+00, -1.9856e+00,  4.9877e-01,  1.0367e-01,\n",
       "         2.9025e-01, -4.5573e-01,  8.0964e-01, -1.5484e+00, -5.6441e-01,\n",
       "        -4.5943e-02, -1.1568e+00,  3.8699e-01,  5.5779e-01, -8.0672e-01,\n",
       "        -2.0174e+00, -6.6912e-01,  3.0506e-01, -1.6672e+00,  2.3217e+00,\n",
       "        -2.0927e+00,  6.6937e-01, -1.4029e-01,  7.3527e-01, -5.4498e-01,\n",
       "        -7.9189e+00,  8.0708e-01,  1.7495e+00,  4.2754e-01, -6.6161e-02,\n",
       "         8.9618e-01,  4.3346e-01,  7.1985e-01, -7.8421e-02,  7.2757e-01,\n",
       "         4.8322e+00, -1.7774e+00, -7.6385e-01,  1.5116e+00,  4.3638e-01,\n",
       "         2.8500e+00,  7.3823e-01, -2.0385e+00,  4.6693e-01, -5.2033e-01,\n",
       "        -3.3623e+00,  7.6799e-01, -7.3129e-02,  6.9136e-02, -6.0299e-01,\n",
       "        -8.7606e-01,  2.5982e-01, -8.0519e-01, -7.4100e-01, -1.7552e+00,\n",
       "        -4.8002e-02, -3.5067e-01, -4.2120e-01, -4.9140e-01, -1.0515e+00,\n",
       "         2.7224e-01, -1.2232e+00,  3.3634e-01, -5.0232e-01,  5.4078e-01,\n",
       "        -6.0802e-01, -1.5326e-01, -4.6332e-01,  3.1284e-01, -1.2230e-01,\n",
       "        -9.1377e-02,  3.3080e+00,  5.8486e+00,  2.0056e-01,  1.4661e+00,\n",
       "         1.3445e-01, -4.4402e-01, -1.6285e+00,  4.9653e-01,  4.5763e-01,\n",
       "         6.9742e-01,  2.1412e+00, -9.3026e-01,  5.2545e-01, -2.2277e-01,\n",
       "        -1.2766e+00, -9.7877e-01, -1.2845e+00,  8.0700e-02, -1.2074e+00,\n",
       "        -1.2251e-01,  8.7592e-01,  1.2113e+00,  3.8063e-01, -1.5716e+00,\n",
       "        -4.2013e-01, -2.4067e-01, -1.0410e-01, -9.2978e-01,  5.9777e-01,\n",
       "        -3.6116e-01, -1.7735e-01, -1.2348e+00, -5.2285e-01, -7.7811e-01,\n",
       "        -1.5687e+00, -3.3629e-01, -2.0820e+00, -3.8651e-01, -8.4330e-01,\n",
       "        -5.3089e-02, -6.0520e-01,  4.8422e-01, -1.3175e-01,  6.7730e-01,\n",
       "         5.2908e-02, -6.0696e-01, -3.6854e-02,  2.2119e+00, -3.0133e-01,\n",
       "        -1.2387e+00,  5.2648e-01, -3.5478e-01,  2.1212e-01,  3.7775e-01,\n",
       "        -2.1096e+00, -1.0394e+00, -1.9685e-01, -8.6300e-02,  6.2793e+00,\n",
       "        -4.2801e+00,  1.4780e-02,  1.1275e+00, -1.2075e+00, -1.0118e+00,\n",
       "         1.2964e+00, -5.3194e-01,  1.7170e+00, -1.1201e+00, -1.3997e+00,\n",
       "         8.0820e-01, -1.5263e-01, -1.8760e+00,  3.0000e-01,  7.8007e-01,\n",
       "        -2.0863e-01, -6.0796e-01, -1.8553e+00, -1.4357e-01,  3.1612e-01,\n",
       "         7.4647e-01,  1.1601e+00, -1.2118e+00,  7.9793e+00,  1.6554e+00,\n",
       "        -2.6062e+00,  4.2747e+00, -9.7052e-01, -7.0851e-01, -1.6031e-01,\n",
       "        -1.4741e+00, -3.3491e-01,  2.2390e-01,  1.2445e+00,  1.7118e+00,\n",
       "        -2.8825e+00, -8.4207e-01,  9.4800e-01, -1.9181e+00,  1.0838e-01,\n",
       "        -8.8410e-02,  1.5517e+00,  4.6970e-01, -1.0647e-01,  3.4728e-01,\n",
       "        -7.9688e-01, -7.7973e-02,  7.6103e-01,  6.8649e-01,  2.1064e+00,\n",
       "        -5.7213e-01,  2.1474e+00,  9.0215e-01, -1.6336e-01, -4.1466e-01,\n",
       "        -3.6872e-01, -2.8095e-01,  9.3889e-01, -1.7521e+00,  1.0494e+00,\n",
       "        -4.6898e-01,  3.6916e-01, -3.4105e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_index(sentence, word):\n",
    "     return sentence.split(\" \").index(word)\n",
    " \n",
    " \n",
    "def get_hidden_states(encoded, token_ids_word, model, layers):\n",
    "     with torch.no_grad():\n",
    "         output = model(**encoded)\n",
    " \n",
    "     states = output.hidden_states\n",
    "     output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "     word_tokens_output = output[token_ids_word]\n",
    " \n",
    "     return word_tokens_output.mean(dim=0)\n",
    " \n",
    " \n",
    "def get_embeddings(sentence, idx, tokenizer, model, layers):\n",
    "     encoded = tokenizer.encode_plus(sentence, return_tensors=\"pt\")\n",
    "     token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    " \n",
    "     return get_hidden_states(encoded, token_ids_word, model, layers)\n",
    "   \n",
    "layers = [-4, -3, -2, -1]\n",
    "sentence = \"هلا كيف الحال\" \n",
    "idx = word_index(sentence, \"هلا\")\n",
    "word_embedding = get_embeddings(sentence, idx, tokenizer, model, layers)\n",
    "\n",
    "word_embedding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40840/157746958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"هلا\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\SHIT\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\SHIT\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    185\u001b[0m     ):\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "model.base_model.embeddings(np.array(\"هلا\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(64000, 768, padding_idx=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
