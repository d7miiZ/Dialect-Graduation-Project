{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dd148e",
   "metadata": {},
   "source": [
    "# Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa44ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for one time and then restart the kernal and don't run it agian\n",
    "# !pip install optuna==2.3.0\n",
    "# !pip install transformers==4.2.1\n",
    "# !pip install farasapy\n",
    "# !pip install pyarabic\n",
    "# !git clone https://github.com/aub-mind/arabert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab8b8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "import logging\n",
    "import torch\n",
    "import optuna \n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ef8ab",
   "metadata": {},
   "source": [
    "# Data  Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "039def19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SMADC_folder_data():\n",
    "    \"\"\"Returns a dataframe with Text and Region columns. Requires tree like this data/SMADC/*.txt\"\"\"\n",
    "    files = glob.glob(\"data/SMADC/*.txt\")\n",
    "    dataframes = []\n",
    "\n",
    "    for file in files:\n",
    "        region = file[-7:-4]\n",
    "        temp_df = pd.read_csv(file, encoding=\"utf8\", delimiter=\"\\n\", names=[\"Text\"])\n",
    "        temp_df[\"Region\"] = region\n",
    "        dataframes.append(temp_df)\n",
    "        \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22f73421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(path_to_model, return_dict=True, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "345f2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could add any metric you want\n",
    "def compute_metrics(p): \n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    assert len(preds) == len(p.label_ids)\n",
    "\n",
    "    macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
    "    macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
    "    macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
    "    acc = accuracy_score(p.label_ids,preds)\n",
    "    return {\n",
    "      'macro_f1' : macro_f1,\n",
    "      'macro_precision': macro_precision,\n",
    "      'macro_recall': macro_recall,\n",
    "      'accuracy': acc\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97be3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        train,\n",
    "        test,\n",
    "        label_list,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.label_list = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e911c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, text, target, model_name, max_len, label_map):\n",
    "        super(BERTDataset).__init__()\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.tokenizer_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.max_len = max_len\n",
    "        self.label_map = label_map\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        text = str(self.text[item])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          truncation='longest_first'\n",
    "          )\n",
    "    \n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad to the max length.\n",
    "        padding_length = self.max_len - len(input_ids)\n",
    "        input_ids = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
    "        attention_mask = attention_mask + ([0] * padding_length)\n",
    "    \n",
    "        return InputFeatures(input_ids=input_ids, attention_mask=attention_mask, label=self.label_map[self.target[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b55daea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_SMADC_folder_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53f9289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"text\", \"label\"]\n",
    "label_list_df = [\"EGY\", \"NOR\",\"LEV\",\"GLF\",\"IRQ\"]\n",
    "#print(df[\"label\"].value_counts())\n",
    "train_set, test_set = train_test_split(df, test_size=0.8, random_state=42)\n",
    "data_dilect = Dataset(\"Dilect\", train_set, test_set, label_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb74f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-09-08 17:37:45,590 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    }
   ],
   "source": [
    "model_name=\"bert-base-arabertv2\"\n",
    "max_len = 200\n",
    "text = \"ولن نبالغ إذا قلنا إن هاتف أو كمبيوتر المكتب في زمننا هذا ضروري\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "#arabert_prep.preprocess(df.head(1)[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7f1751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060\n",
      "Wed Sep  8 17:37:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 466.11       Driver Version: 466.11       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 53%   50C    P2    44W / 170W |   4648MiB / 12288MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1332    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      3288    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      3788    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      6812    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      7192    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      7508      C   ...cast\\NVIDIA Broadcast.exe    N/A      |\n",
      "|    0   N/A  N/A      8688    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10544    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     11992    C+G   ...zer\\Synapse\\RzSynapse.exe    N/A      |\n",
      "|    0   N/A  N/A     13164    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17336    C+G   ...in7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     18220    C+G   ...\\app-1.0.9002\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     20412    C+G   ...\\app-1.0.9002\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     20840    C+G   C:\\Softwarez\\Steam\\steam.exe    N/A      |\n",
      "|    0   N/A  N/A     23820      C   ...on\\Python3.9.5\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     24240      C   ...on\\Python3.9.5\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    !nvidia-smi\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b5e0cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohnd\\AppData\\Local\\Temp/ipykernel_23820/2730620555.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_dilect.train[\"text\"] = data_dilect.train[\"text\"].apply(lambda text:arabert_prep.preprocess(text))\n",
      "C:\\Users\\mohnd\\AppData\\Local\\Temp/ipykernel_23820/2730620555.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_dilect.test[\"text\"] = data_dilect.test[\"text\"].apply(lambda text:arabert_prep.preprocess(text))\n"
     ]
    }
   ],
   "source": [
    "data_dilect.train[\"text\"] = data_dilect.train[\"text\"].apply(lambda text:arabert_prep.preprocess(text))\n",
    "data_dilect.test[\"text\"] = data_dilect.test[\"text\"].apply(lambda text:arabert_prep.preprocess(text))\n",
    "#print(data_dilect.train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "110f802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/vocab.txt from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\6d195dfa0ab2ff9e30278a35699eb13eeb3a69731e8458ef8af7c9598e05ee99.292c9b563974181697c28c4ae4b6899dcaa7bdcf146b5682a389ef18208389a9\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\cdf2434ef735735269b56feeae539fb93d28d674f4b335e2f08ed38960ea51e7.cf8d1bcc109a4ae89b00382b3c7dce421b2534c25751be3d5156322fc427fc12\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/special_tokens_map.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\4318ddb7acd24ce55328cd47235c5aaf88d4925a8a257863c4ebcc0852985d2c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer_config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\f8b57973211cf183180900e4646e204fe0c492b6129df1509f0e8ddc02369a05.130b8595f3c840efdfe3e2e9d3926b3c47a1a69aa1a7f6660fd11be56bf0d5fc\n",
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/vocab.txt from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\6d195dfa0ab2ff9e30278a35699eb13eeb3a69731e8458ef8af7c9598e05ee99.292c9b563974181697c28c4ae4b6899dcaa7bdcf146b5682a389ef18208389a9\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\cdf2434ef735735269b56feeae539fb93d28d674f4b335e2f08ed38960ea51e7.cf8d1bcc109a4ae89b00382b3c7dce421b2534c25751be3d5156322fc427fc12\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/special_tokens_map.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\4318ddb7acd24ce55328cd47235c5aaf88d4925a8a257863c4ebcc0852985d2c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer_config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\f8b57973211cf183180900e4646e204fe0c492b6129df1509f0e8ddc02369a05.130b8595f3c840efdfe3e2e9d3926b3c47a1a69aa1a7f6660fd11be56bf0d5fc\n",
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_model = \"aubmindlab/bert-base-arabertv02\"\n",
    "label_map = { v:index for index, v in enumerate(data_dilect.label_list) }\n",
    "#print(label_map)\n",
    "train_dataset = BERTDataset(data_dilect.train[\"text\"].to_list(),data_dilect.train[\"label\"].to_list(),path_to_model,max_len,label_map)\n",
    "test_dataset = BERTDataset(data_dilect.test[\"text\"].to_list(),data_dilect.test[\"label\"].to_list(),path_to_model,max_len,label_map)\n",
    "#print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe08f7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb5a2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "27500\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"./train\")\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.adam_epsilon = 1e-8\n",
    "training_args.learning_rate = 5e-5\n",
    "training_args.fp16 = True\n",
    "training_args.per_device_train_batch_size = 128\n",
    "training_args.per_device_eval_batch_size = 128\n",
    "training_args.gradient_accumulation_steps = 2\n",
    "training_args.num_train_epochs= 25\n",
    "\n",
    "\n",
    "steps_per_epoch = (len(data_dilect.train)// (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\n",
    "total_steps = steps_per_epoch * training_args.num_train_epochs\n",
    "print(steps_per_epoch)\n",
    "print(total_steps)\n",
    "#Warmup_ratio\n",
    "warmup_ratio = 0.1\n",
    "training_args.warmup_steps = total_steps*warmup_ratio # or you can set the warmup steps directly \n",
    "\n",
    "training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
    "# training_args.logging_steps = 200\n",
    "training_args.save_steps = 100000 #don't want to save any model, there is probably a better way to do this :)\n",
    "training_args.seed = 42\n",
    "training_args.disable_tqdm = False\n",
    "training_args.lr_scheduler_type = 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "611604f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = trainer.model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fbddce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 281691\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 220075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220075' max='220075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220075/220075 24:44:57, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mohnd\\desktop\\delete me\\venv\\lib\\site-packages\\transformers\\trainer.py:1312: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "Saving model checkpoint to ./train\\checkpoint-100000\n",
      "Configuration saved in ./train\\checkpoint-100000\\config.json\n",
      "Model weights saved in ./train\\checkpoint-100000\\pytorch_model.bin\n",
      "c:\\users\\mohnd\\desktop\\delete me\\venv\\lib\\site-packages\\transformers\\trainer.py:1312: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "Saving model checkpoint to ./train\\checkpoint-200000\n",
      "Configuration saved in ./train\\checkpoint-200000\\config.json\n",
      "Model weights saved in ./train\\checkpoint-200000\\pytorch_model.bin\n",
      "c:\\users\\mohnd\\desktop\\delete me\\venv\\lib\\site-packages\\transformers\\trainer.py:1312: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=220075, training_loss=0.12656088520258268, metrics={'train_runtime': 89098.1632, 'train_samples_per_second': 79.04, 'train_steps_per_second': 2.47, 'total_flos': 7.2380871746901e+17, 'train_loss': 0.12656088520258268, 'epoch': 25.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536efaa8",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f06454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to 25_epoch\n",
      "Configuration saved in 25_epoch\\config.json\n",
      "Model weights saved in 25_epoch\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"25_epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eeb9e9",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0dac718",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = [\"آني ذاك الظلت عيونه عليج وماكدر يخطيله خطوه\"\n",
    "              ,\"هو فعلا مفيش مدرب مصري يصلح وفعلا تاكيس جونياس كويس لاكن لو قدرنا نجيب مدرب اجنبي افضل يبقي تمام ولو اتحاد الكوره موصر علي مدرب مصري يبقي حسام حسن مفيش غيره\",\n",
    "             \"هاض عرس سوري مش اردني تحياتي لك من ادلب\",\n",
    "             \"وا ماكدبوش ملي قالو لا تيقة فيك اليام ولاد ناس فيك قلالو و لبنات كرهو الغرام\",\n",
    "             \"اذا في يوم من الايام صرت قد كلامك تعال انا موجود \",\n",
    "             \"في ظلام الليل نسير نافيغي زماني نزدم وندير ندير نحقق الاماني\",\n",
    "            \"يا خبر النهاردة بفلوس بكره ينزل عليه أوكازيون\",\n",
    "            \"انفخ يا شريم قال ماكو برطم\",\n",
    "            \"كثرة الدق يفج اللحام\"]\n",
    "text_label = [\"IRQ\",\"EGY\",\"LEV\",\"NOR\",\"GLF\",\"NOR\",\"EGY\",\"GLF\",\"GLF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b795fe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/vocab.txt from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\6d195dfa0ab2ff9e30278a35699eb13eeb3a69731e8458ef8af7c9598e05ee99.292c9b563974181697c28c4ae4b6899dcaa7bdcf146b5682a389ef18208389a9\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\cdf2434ef735735269b56feeae539fb93d28d674f4b335e2f08ed38960ea51e7.cf8d1bcc109a4ae89b00382b3c7dce421b2534c25751be3d5156322fc427fc12\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/special_tokens_map.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\4318ddb7acd24ce55328cd47235c5aaf88d4925a8a257863c4ebcc0852985d2c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/tokenizer_config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\f8b57973211cf183180900e4646e204fe0c492b6129df1509f0e8ddc02369a05.130b8595f3c840efdfe3e2e9d3926b3c47a1a69aa1a7f6660fd11be56bf0d5fc\n",
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\411eec8d9e12bf4c11eebebb4c5fecd46da787616f45bcfd6cb187e0917afae0.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_token = []\n",
    "for text in text_test:\n",
    "    text_token.append(arabert_prep.preprocess(text))\n",
    "text_token_set = BERTDataset(text_token,text_label,path_to_model,max_len,label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eee2b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2371' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 11:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 1, 3, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pred, _, _ = trainer.predict(text_token_set)\n",
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb0d0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"EGY\": 0,\n",
    "#\"NOR\": 1,\n",
    "#\"LEV\": 2,\n",
    "#\"GLF\": 3,\n",
    "#\"IRQ\": 4,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d02ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1126765\n",
      "  Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8803' max='8803' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8803/8803 1:30:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4585100412368774,\n",
       " 'eval_macro_f1': 0.8017849717637787,\n",
       " 'eval_macro_precision': 0.8067391787039732,\n",
       " 'eval_macro_recall': 0.7971792630112084,\n",
       " 'eval_accuracy': 0.8348067254485185,\n",
       " 'eval_runtime': 5409.7077,\n",
       " 'eval_samples_per_second': 208.286,\n",
       " 'eval_steps_per_second': 1.627}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = epoch25,\n",
    "    args = training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe26a771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputFeatures(input_ids=[2, 9016, 17, 3824, 17, 141, 1045, 838, 17, 138, 113, 17, 31917, 17, 3824, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6908c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch25 = AutoModelForSequenceClassification.from_pretrained(\"25_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005cd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
