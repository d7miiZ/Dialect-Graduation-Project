{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext as ft\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KeyedVectors.load_word2vec_format(\"Embeddings/egy.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_GLF = ft.train_unsupervised(\"../model_and_research/code/data/SMADC/GLF.txt\", dim=512)\n",
    "embedding_EGY = ft.train_unsupervised(\"../model_and_research/code/data/SMADC/EGY.txt\", dim=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_GLF.save_model(\"embedding_GLF.bin\")\n",
    "embedding_EGY.save_model(\"embedding_EGY.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_GLF = ft.load_model(\"embedding_GLF.bin\")\n",
    "# embedding_EGY = ft.load_model(\"embedding_EGY.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-c15372744783>:1: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  gensim.models.FastText.load_fasttext_format('embedding_GLF.bin').wv.save_word2vec_format(\"glf.vec\", binary=False)\n",
      "<ipython-input-8-c15372744783>:2: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  gensim.models.FastText.load_fasttext_format('embedding_EGY.bin').wv.save_word2vec_format(\"egy.vec\", binary=False)\n"
     ]
    }
   ],
   "source": [
    "gensim.models.FastText.load_fasttext_format('embedding_GLF.bin').wv.save_word2vec_format(\"glf.vec\", binary=False)\n",
    "gensim.models.FastText.load_fasttext_format('embedding_EGY.bin').wv.save_word2vec_format(\"egy.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "glf_model = KeyedVectors.load_word2vec_format(\"Embeddings/gulf.bin\", binary=True)\n",
    "egy_mapped_glf_model = KeyedVectors.load_word2vec_format(\"Embeddings/egy.mappedToGulf.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets find closes words to المهم in Egyptian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = glf_model[\"AlmHl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AlmHl', 0.5118714570999146),\n",
       " ('bAb_AlmHl', 0.4419998526573181),\n",
       " ('AlmHlAt', 0.42778298258781433),\n",
       " ('AlmHlAjp', 0.41190841794013977),\n",
       " ('wAlmHl', 0.40494096279144287),\n",
       " ('EAlmHl', 0.4009820520877838),\n",
       " ('SAHb_AlmHl', 0.39808666706085205),\n",
       " ('AlmHlk', 0.39755794405937195),\n",
       " ('AlmHfZ', 0.39437544345855713),\n",
       " ('hAlmHl', 0.39232826232910156)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egy_mapped_glf_model.similar_by_vector(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = egyglf_model.key_to_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AlA_bAllh', 0.8093166947364807),\n",
       " ('Aqsm_bAllh', 0.7836987376213074),\n",
       " ('wAqsm_bAllh', 0.7669810056686401),\n",
       " ('AlcqA_bAllh', 0.7669002413749695),\n",
       " ('AlZn_bAllh', 0.7384269833564758),\n",
       " ('qwh_AlA_bAllh', 0.7319467067718506),\n",
       " ('qwp_AlA_bAllh', 0.7169179320335388),\n",
       " ('yWmn_bAllh', 0.7151197195053101),\n",
       " ('wlAqwh_AlA_bAllh', 0.709934651851654),\n",
       " ('lAqwp_AlA_bAllh', 0.7093310952186584)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egy_mapped_glf_model.similar_by_word(\"qsmA_bAllh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a11609d3c9a3d6d9d27250456fa90a271920de06fcd2ad5e9bde9ece7a63280"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('graduation_project')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
