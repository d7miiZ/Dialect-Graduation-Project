{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.realpath(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import fasttext as ft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import umap.plot\n",
    "import hdbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import utilities\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = utilities.get_arabic_lexicon_data(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "glf_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"glf.vec\"))\n",
    "egy_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"egy.vec\"))\n",
    "irq_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"irq.vec\"))\n",
    "nor_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"nor.vec\"))\n",
    "lev_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"lev.vec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emotion_lexicon(embedding, emotion, min_cluster_size, num_words_to_generate=100, verbose=False, save=False, embedding_name=None):\n",
    "    if save:\n",
    "        assert embedding_name is not None, \"embedding_name must not be None when trying to save\" \n",
    "    \n",
    "    lexicon = utilities.get_arabic_lexicon_data(\"..\")\n",
    "    def get(embedding, val, default=None):\n",
    "        try:\n",
    "            return embedding[val]\n",
    "        except KeyError:\n",
    "            return default\n",
    "\n",
    "    emotions = list(lexicon.keys())\n",
    "    if verbose:\n",
    "        print(f\"Emotions in lexicon {emotions}\")\n",
    "    assert emotion in lexicon, f\"The emotion {emotion} is not in the Lexicon\"\n",
    "\n",
    "    vecs_non_filtered = list(map(lambda wrd: get(glf_embedding, wrd, default=None), lexicon[emotion]))\n",
    "    if verbose:\n",
    "        print(f\"Number of words considered {sum(1 for vec in vecs_non_filtered if vec is not None)}/{len(vecs_non_filtered)}\")\n",
    "    vecs = list(filter(lambda x: x is not None, vecs_non_filtered))\n",
    "    centroid = np.mean(vecs, axis=0)\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster_labels = clusterer.fit_predict(vecs)\n",
    "\n",
    "    if verbose:\n",
    "        print(cluster_labels)\n",
    "    cluster_to_words = {}\n",
    "    for focus_cluster in np.unique(cluster_labels):\n",
    "        clustered_vecs = [vec for cluster, vec in zip(cluster_labels, vecs) if cluster == focus_cluster]\n",
    "        clustered_centroid = np.median(clustered_vecs, axis=0)\n",
    "        cluster_to_words[focus_cluster] = list(zip(*glf_embedding.similar_by_vector(clustered_centroid, num_words_to_generate)))[0]\n",
    "\n",
    "    if verbose:\n",
    "        mapper = umap.UMAP().fit(vecs)\n",
    "        umap.plot.points(mapper, labels=cluster_labels)\n",
    "    df = pd.DataFrame(cluster_to_words)\n",
    "    style = df.style.applymap(lambda x: \"background-color: rgba(20, 20, 20, 1)\" if x in lexicon[emotion] else \"\")\n",
    "    if save:\n",
    "        df.to_csv(f\"emotion_lexicon/{embedding_name}_{emotion}_minclustersize={min_cluster_size}.csv\")\n",
    "    return style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with using all words in generating similar words\n",
    "### Solution: cluster the vector representation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>فی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ضفدع</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لعنبو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ض</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نذل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>قذف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>شآء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>آللـہ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ضب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>رآي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>كى</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>غ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>هتلر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>يذم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ֆء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ضف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>٤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>خائن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>مؤبد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       -1\n",
       "0      فی\n",
       "1    ضفدع\n",
       "2   لعنبو\n",
       "3       ض\n",
       "4     نذل\n",
       "5     ***\n",
       "6     قذف\n",
       "7     شآء\n",
       "8   آللـہ\n",
       "9      ضب\n",
       "10    رآي\n",
       "11     كى\n",
       "12      غ\n",
       "13   هتلر\n",
       "14    يذم\n",
       "15     ֆء\n",
       "16     ضف\n",
       "17      ٤\n",
       "18   خائن\n",
       "19   مؤبد"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, emotion=\"anger\", min_cluster_size=100, num_words_to_generate=500)\n",
    "df.data.iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with centroid idea\n",
    "### Solution(?): Maybe decrease the min_cluster_size?\n",
    "![img](https://www.researchgate.net/profile/Fotios-Katsilieris-2/publication/239926467/figure/fig4/AS:669426328301595@1536615082633/An-example-of-the-difference-between-a-convex-and-a-non-convex-region.ppm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the centroid with the mean seems to give worse performance than finding it with the median. Probably since the mean is swayed by outlier vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### For some reason, Arabic embeddings favor ryhming words\n",
    "### Possible reasons: Bad data, Arabic itself has ryhming words closeby, so CBOW and Skipgram think they're similar in meaning\n",
    "![img](https://i.imgur.com/7XKYaBI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, emotion=\"anger\", min_cluster_size=8, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, emotion=\"joy\", min_cluster_size=15, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, emotion=\"disgust\", min_cluster_size=3, num_words_to_generate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=egy_embedding, emotion=\"joy\", min_cluster_size=13, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=egy_embedding, emotion=\"fear\", min_cluster_size=7, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=lev_embedding, emotion=\"disgust\", min_cluster_size=5, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=nor_embedding, emotion=\"sadness\", min_cluster_size=30, num_words_to_generate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=nor_embedding, emotion=\"anger\", min_cluster_size=15, num_words_to_generate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a11609d3c9a3d6d9d27250456fa90a271920de06fcd2ad5e9bde9ece7a63280"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('graduation_project')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
