{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.realpath(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import umap.plot\n",
    "import hdbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import utilities\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = utilities.get_arabic_lexicon_data(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "glf_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"glf.vec\"))\n",
    "egy_embedding = KeyedVectors.load_word2vec_format(join(\"embeddings\", \"egy.vec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emotion_lexicon(embedding, embedding_name, emotion, min_cluster_size, num_words_to_generate=100, verbose=False, save=False):\n",
    "    lexicon = utilities.get_arabic_lexicon_data(\"..\")\n",
    "    def get(embedding, val, default=None):\n",
    "        try:\n",
    "            return embedding[val]\n",
    "        except KeyError:\n",
    "            return default\n",
    "\n",
    "    emotions = list(lexicon.keys())\n",
    "    if verbose:\n",
    "        print(f\"Emotions in lexicon {emotions}\")\n",
    "    assert emotion in lexicon, f\"The emotion {emotion} is not in the Lexicon\"\n",
    "\n",
    "    vecs_non_filtered = list(map(lambda wrd: get(glf_embedding, wrd, default=None), lexicon[emotion]))\n",
    "    if verbose:\n",
    "        print(f\"Number of words outside the vocabulary {sum(1 for vec in vecs_non_filtered if vec is not None)}/{len(vecs_non_filtered)}\")\n",
    "    vecs = list(filter(lambda x: x is not None, vecs_non_filtered))\n",
    "    centroid = np.mean(vecs, axis=0)\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster_labels = clusterer.fit_predict(vecs)\n",
    "\n",
    "    if verbose:\n",
    "        print(cluster_labels)\n",
    "    cluster_to_words = {}\n",
    "    for focus_cluster in np.unique(cluster_labels):\n",
    "        clustered_vecs = [vec for cluster, vec in zip(cluster_labels, vecs) if cluster == focus_cluster]\n",
    "        clustered_centroid = np.mean(clustered_vecs, axis=0)\n",
    "        cluster_to_words[focus_cluster] = list(zip(*glf_embedding.similar_by_vector(clustered_centroid, num_words_to_generate)))[0]\n",
    "\n",
    "    if verbose:\n",
    "        mapper = umap.UMAP().fit(vecs)\n",
    "        umap.plot.points(mapper, labels=cluster_labels)\n",
    "    df = pd.DataFrame(cluster_to_words)\n",
    "    style = df.style.applymap(lambda x: \"background-color: rgba(20, 20, 20, 1)\" if x in lexicon[emotion] else \"\")\n",
    "    if save:\n",
    "        df.to_csv(f\"emotion_lexicon/{embedding_name}_{emotion}_minclustersize={min_cluster_size}.csv\")\n",
    "    return style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with using all words in generating similar words\n",
    "### Solution: cluster the vector representation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>فی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ضفدع</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ض</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>شآء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>***</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>لعنبو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>رآي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ضب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>نذل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>فاسق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ضف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ث</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>آللـہ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>قذف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>هتلر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>مؤبد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>غ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>مخنوق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>غاضب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>كى</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       -1\n",
       "0      فی\n",
       "1    ضفدع\n",
       "2       ض\n",
       "3     شآء\n",
       "4     ***\n",
       "5   لعنبو\n",
       "6     رآي\n",
       "7      ضب\n",
       "8     نذل\n",
       "9    فاسق\n",
       "10     ضف\n",
       "11      ث\n",
       "12  آللـہ\n",
       "13    قذف\n",
       "14   هتلر\n",
       "15   مؤبد\n",
       "16      غ\n",
       "17  مخنوق\n",
       "18   غاضب\n",
       "19     كى"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, embedding_name=\"glf\", emotion=\"anger\", min_cluster_size=100, num_words_to_generate=500)\n",
    "df.data.iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem with centroid idea\n",
    "### Solution(?): Maybe decrease the min_cluster_size?\n",
    "![img](https://www.researchgate.net/profile/Fotios-Katsilieris-2/publication/239926467/figure/fig4/AS:669426328301595@1536615082633/An-example-of-the-difference-between-a-convex-and-a-non-convex-region.ppm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, embedding_name=\"glf\", emotion=\"anger\", min_cluster_size=8, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, embedding_name=\"glf\", emotion=\"joy\", min_cluster_size=15, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=glf_embedding, embedding_name=\"glf\", emotion=\"disgust\", min_cluster_size=3, num_words_to_generate=100, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=egy_embedding, embedding_name=\"egy\", emotion=\"joy\", min_cluster_size=13, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_emotion_lexicon(embedding=egy_embedding, embedding_name=\"egy\", emotion=\"fear\", min_cluster_size=7, num_words_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a11609d3c9a3d6d9d27250456fa90a271920de06fcd2ad5e9bde9ece7a63280"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('graduation_project')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
