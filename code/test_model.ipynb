{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from pickle import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer, EarlyStoppingCallback, BatchEncoding\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "import optuna\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing params\n",
    "sequence_length: int = 32 # Not sure what happens when setting it with a number different from what its trained on\n",
    "\n",
    "# Model \n",
    "model_name: str = \"aubmindlab/bert-large-arabertv2\"\n",
    "pretrained_classifier_name: str = \"2021-12-09-train-0.963134765625\"\n",
    "\n",
    "# Data\n",
    "df: pd.DataFrame = get_annotated_data_folder_data()\n",
    "\n",
    "# Paths\n",
    "code_folder_path: str = \"\"\n",
    "\n",
    "# Training \n",
    "batch_size: int = 64\n",
    "\n",
    "# Etc\n",
    "open_tensorboard: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-11 18:07:25,695 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "label2id = pretrained_classifier.config.label2id\n",
    "id2label = pretrained_classifier.config.id2label\n",
    "\n",
    "# Model\n",
    "pretrained_classifier_path = join(code_folder_path, \"models\", \"finalized_models\", pretrained_classifier_name) \n",
    "pretrained_classifier = AutoModelForSequenceClassification.from_pretrained(pretrained_classifier_path)\n",
    "arabert_prep = ArabertPreprocessor(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df[\"Labels\"] = df[\"Region\"].apply(label2id.get)\n",
    "df[\"Text\"] = df[\"Text\"].apply(arabert_prep.preprocess)\n",
    "df_encoding = tokenize(tokenizer, df[\"Text\"].to_list(), sequence_length)\n",
    "\n",
    "test_set = Dialect_dataset(df_encoding, df[\"Labels\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 26804\n",
      "  Batch size = 8\n",
      "100%|█████████▉| 3349/3351 [02:53<00:00, 20.45it/s]D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.460561752319336,\n",
       " 'test_macro_f1': 0.060848385158004614,\n",
       " 'test_macro_precision': 0.0358827040740188,\n",
       " 'test_macro_recall': 0.2,\n",
       " 'test_accuracy': 0.179413520370094,\n",
       " 'test_runtime': 198.7829,\n",
       " 'test_samples_per_second': 134.841,\n",
       " 'test_steps_per_second': 16.858}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3351/3351 [03:10<00:00, 20.45it/s]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=pretrained_classifier, compute_metrics=compute_metrics)\n",
    "prediction = trainer.predict(test_set)\n",
    "prediction.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.179413520370094"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [np.argmax(pred) for pred in prediction[0]]\n",
    "y_true = df[\"Labels\"]\n",
    "accuracy_score(y_true , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3556/4272850237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"والله مابعرف اغلب الناس رواتبها ومش ععارفين كيف ممشين هاذ بوخذ الاف وعدا عن السيارات والبدل والسفرات والخ وبحكيلك قليل هو الفساد بيجي من قليل\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredict_dialect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marabert_prep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"والله مابعرف اغلب الناس رواتبها ومش ععارفين كيف ممشين هاذ بوخذ الاف وعدا عن السيارات والبدل والسفرات والخ وبحكيلك قليل هو الفساد بيجي من قليل\" \n",
    "predict_dialect(model_path, text, tokenizer, arabert_prep.preprocess, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
