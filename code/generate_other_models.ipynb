{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "code_folder_path = \"\"\n",
    "data_percentage = 0.001 # how much of the data we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "stack_estimators = [\n",
    "    ('NaiveBayes', make_pipeline(DenseTransformer(), GaussianNB())),\n",
    "    ('DecisionTree', DecisionTreeClassifier(max_depth=100)),\n",
    "    ('SVM', SVC(kernel=\"linear\", C=0.6)),\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=1000, random_state=random_state))\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    # \"RBF SVM\", # Bad performance\n",
    "#     \"Gaussian Process\", \n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "#     \"Neural Net\", # Too slow\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    # \"QDA\", # Terrible performance\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    StackingClassifier(estimators=stack_estimators, final_estimator=DecisionTreeClassifier(max_depth=5)),\n",
    "    SVC(kernel=\"linear\", C=0.5),\n",
    "    # SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=60),\n",
    "    # RandomForestClassifier(max_depth=5, n_estimators=100),\n",
    "    # MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    # QuadraticDiscriminantAnalysis(), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_SMADC_folder_data()\n",
    "df = df.sample(frac=data_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 297 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Text\"], df[\"Region\"], random_state=random_state)\n",
    "# count_vectorizer = CountVectorizer()\n",
    "count_vectorizer = TfidfVectorizer()\n",
    "X_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "standard_scaler = StandardScaler(with_mean=False).fit(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.4559909142532652\n",
      "StackClassifier 0.6607041453719478\n",
      "Linear SVM 0.5857467348097671\n",
      "Decision Tree 0.5570698466780238\n",
      "AdaBoost 0.6391254968767746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.4514480408858603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name, clf in zip(names, classifiers):\n",
    "    if name in (\"Naive Bayes\", \"Gaussian Process\", \"QDA\"):\n",
    "        model = make_pipeline(count_vectorizer, standard_scaler, DenseTransformer(), clf)\n",
    "    else:\n",
    "        model = make_pipeline(count_vectorizer, standard_scaler, clf)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(name, score, flush=True)\n",
    "    joblib.dump(model, join(code_folder_path, f\"models/other_models/{name}_acc={score.round(3)}.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', make_pipeline(count_vectorizer,RandomForestClassifier(max_depth=5, n_estimators=100, random_state=42))),\n",
    "    ('svr', make_pipeline(count_vectorizer,SVC(gamma=2, C=1))),\n",
    "    (\"ada\", make_pipeline(count_vectorizer,AdaBoostClassifier()))\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=DecisionTreeClassifier(max_depth=5)\n",
    ")\n",
    "clf.fit(X_train,y_train).score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
