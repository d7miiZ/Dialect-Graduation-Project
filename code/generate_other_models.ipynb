{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "code_folder_path = \"\"\n",
    "data_percentage = 0.001 # how much of the data we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17104/3723282386.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'DecisionTree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'SVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[1;34m\"LogisticRegression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "stack_estimators = [\n",
    "    ('NaiveBayes', make_pipeline(DenseTransformer(), GaussianNB())),\n",
    "    ('DecisionTree', DecisionTreeClassifier(max_depth=100)),\n",
    "    ('SVM', SVC(kernel=\"linear\", C=0.6)),\n",
    "    # (\"LogisticRegression\", LogisticRegression(max_iter=1000, random_state=random_state))\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    # \"RBF SVM\", # Bad performance\n",
    "#     \"Gaussian Process\", \n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "#     \"Neural Net\", # Too slow\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    # \"QDA\", # Terrible performance\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    StackingClassifier(estimators=stack_estimators, final_estimator=DecisionTreeClassifier(max_depth=5)),\n",
    "    SVC(kernel=\"linear\", C=0.5),\n",
    "    # SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=60),\n",
    "    # RandomForestClassifier(max_depth=5, n_estimators=100),\n",
    "    # MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    # QuadraticDiscriminantAnalysis(), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_SMADC_folder_data()\n",
    "df = df.sample(frac=data_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 297 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Text\"], df[\"Region\"], random_state=random_state)\n",
    "# count_vectorizer = CountVectorizer()\n",
    "count_vectorizer = TfidfVectorizer()\n",
    "X_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "standard_scaler = StandardScaler(with_mean=False).fit(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.4559909142532652\n",
      "StackClassifier 0.6607041453719478\n",
      "Linear SVM 0.5857467348097671\n",
      "Decision Tree 0.5570698466780238\n",
      "AdaBoost 0.6391254968767746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.4514480408858603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name, clf in zip(names, classifiers):\n",
    "    if name in (\"Naive Bayes\", \"Gaussian Process\", \"QDA\"):\n",
    "        model = make_pipeline(count_vectorizer, standard_scaler, DenseTransformer(), clf)\n",
    "    else:\n",
    "        model = make_pipeline(count_vectorizer, standard_scaler, clf)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(name, score, flush=True)\n",
    "    joblib.dump(model, join(code_folder_path, f\"models/other_models/{name}_acc={score.round(3)}.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', make_pipeline(count_vectorizer,RandomForestClassifier(max_depth=5, n_estimators=100, random_state=42))),\n",
    "    ('svr', make_pipeline(count_vectorizer,SVC(gamma=2, C=1))),\n",
    "    (\"ada\", make_pipeline(count_vectorizer,AdaBoostClassifier()))\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=DecisionTreeClassifier(max_depth=5)\n",
    ")\n",
    "clf.fit(X_train,y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models = [\n",
    "    \"MultinomialNaiveBayes_acc=0.865.model\",\n",
    "    \"RandomForest_acc=0.76.model\",\n",
    "    \"Linear SVM_acc=0.747.model\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"annotated_data\": get_annotated_data_folder_data(),\n",
    "    \"arabic_dialects\": get_arabic_dialects_dataset_folder_data(),\n",
    "    \"dart\": get_dart_folder_data()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNaiveBayes_acc=0.865.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_acc=0.76.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM_acc=0.747.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwarez\\Anaconda\\envs\\graduation_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model_path in loaded_models:\n",
    "    print(model_path)\n",
    "    model = joblib.load(join(code_folder_path, \"models\", \"other_models\", model_path))\n",
    "    for name, df in dfs.items():\n",
    "        df = df.dropna()\n",
    "        preds = model.predict(df[\"Text\"])\n",
    "        results.append((\n",
    "            model_path,\n",
    "            name,\n",
    "            model_path[model_path.rindex(\"=\")+1:model_path.rindex(\".\")], # SMADC Accuracy\n",
    "            f1_score(df[\"Region\"], preds, average=\"macro\"),\n",
    "            precision_score(df[\"Region\"], preds, average=\"macro\"),\n",
    "            recall_score(df[\"Region\"], preds, average=\"macro\")\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results, columns=[\"Model name\", \"Dataset\", \"SMADC accuracy\", \"Macro F1\", \"Macro precision\", \"Macro recall\"])\n",
    "df_results[\"Model name\"] = df_results[\"Model name\"].apply(lambda name: name[:name.find(\"_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "           Model name &         Dataset & SMADC accuracy &  Macro F1 &  Macro precision &  Macro recall \\\\\n",
      "\\midrule\n",
      "MultinomialNaiveBayes &  annotated\\_data &          0.865 &  0.552954 &         0.561883 &      0.611622 \\\\\n",
      "MultinomialNaiveBayes & arabic\\_dialects &          0.865 &  0.450884 &         0.464933 &      0.446934 \\\\\n",
      "MultinomialNaiveBayes &            dart &          0.865 &  0.737389 &         0.742771 &      0.748739 \\\\\n",
      "         RandomForest &  annotated\\_data &           0.76 &  0.462519 &         0.497453 &      0.497691 \\\\\n",
      "         RandomForest & arabic\\_dialects &           0.76 &  0.357108 &         0.400919 &      0.357486 \\\\\n",
      "         RandomForest &            dart &           0.76 &  0.667313 &         0.699270 &      0.681225 \\\\\n",
      "           Linear SVM &  annotated\\_data &          0.747 &  0.491982 &         0.524889 &      0.523377 \\\\\n",
      "           Linear SVM & arabic\\_dialects &          0.747 &  0.373722 &         0.418487 &      0.370232 \\\\\n",
      "           Linear SVM &            dart &          0.747 &  0.656211 &         0.698349 &      0.667280 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_results.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a11609d3c9a3d6d9d27250456fa90a271920de06fcd2ad5e9bde9ece7a63280"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('graduation_project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
