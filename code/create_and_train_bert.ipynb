{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import shelve\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from pickle import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer, EarlyStoppingCallback, BatchEncoding\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "import optuna \n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2021-09-30 10:02:21,082 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Data params\n",
    "validation_size = 4096\n",
    "\n",
    "# Model params\n",
    "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Preprocessing params\n",
    "sequence_length = 128\n",
    "arabert_prep = ArabertPreprocessor(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Etc\n",
    "model_string = f\"./models/{str(datetime.today().date())}-train\"\n",
    "dataset_string = \"{}_dataset-seqlen\" + str(sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SMADC_folder_data():\n",
    "    \"\"\"Returns a dataframe with Text and Region columns. Requires tree like this data/SMADC/*.txt\"\"\"\n",
    "    files = glob(\"data/SMADC/*.txt\")\n",
    "    dataframes = []\n",
    "\n",
    "    for file in files:\n",
    "        region = file[-7:-4]\n",
    "        temp_df = pd.read_csv(file, encoding=\"utf8\", delimiter=\"\\n\", names=[\"Text\"])\n",
    "        temp_df[\"Region\"] = region\n",
    "        dataframes.append(temp_df)\n",
    "        \n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "\n",
    "def get_music_df():\n",
    "    files = [\"GLF\",\"LEV\",\"NOR\",\"IRQ\"]\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in files:\n",
    "        temp_df = pd.read_csv(f'../extra_data/d7_data/{file}.txt', encoding=\"utf8\", delimiter=\"\\n\", names=[\"Text\"])\n",
    "        temp_df[\"Region\"] = file\n",
    "        dataframes.append(temp_df)\n",
    "    \n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of strings\n",
    "    \"\"\"\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        batch,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=sequence_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def batch_tokenize_iter(data, batch_size):\n",
    "    len_data = len(data)\n",
    "    batch_num = len_data // batch_size\n",
    "    batch_rest = len_data / batch_size - batch_num\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        yield tokenize(data[i * batch_num:(i+1) * batch_num].to_list())\n",
    "        \n",
    "    if batch_rest:\n",
    "        yield tokenize(data[batch_num:].to_list())\n",
    "\n",
    "\n",
    "def batch_tokenize(data, batch_size):\n",
    "    bt = batch_tokenize_iter(data, batch_size)\n",
    "    for i, tokenization in enumerate(bt):\n",
    "        if not i:\n",
    "            encoding = tokenization\n",
    "            continue\n",
    "        encoding[\"input_ids\"] = torch.cat([encoding[\"input_ids\"], tokenization[\"input_ids\"]])\n",
    "        encoding[\"attention_mask\"] = torch.cat([encoding[\"attention_mask\"], tokenization[\"attention_mask\"]])\n",
    "    return encoding\n",
    "\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    \"\"\"Sample list of strings\"\"\"\n",
    "    return tokenize(list(arabert_prep.preprocess(text) for text in sample))\n",
    "\n",
    "\n",
    "def save_preprocessed_data(dataset, dataset_name):\n",
    "    with open(f\"preprocessed_data/{dataset_name}.pkl\", \"wb\") as file:\n",
    "        dump(dataset, file)\n",
    "        \n",
    "def load_preprocessed_data(dataset_name):\n",
    "    with open(f\"preprocessed_data/{dataset_name}.pkl\", \"rb\") as file:\n",
    "        temp = load(file)\n",
    "    return temp\n",
    "\n",
    "\n",
    "def compute_metrics(p): \n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    assert len(preds) == len(p.label_ids)\n",
    "\n",
    "    macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
    "    macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
    "    macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
    "    acc = accuracy_score(p.label_ids,preds)\n",
    "    return {\n",
    "      'macro_f1' : macro_f1,\n",
    "      'macro_precision': macro_precision,\n",
    "      'macro_recall': macro_recall,\n",
    "      'accuracy': acc\n",
    "    }\n",
    "\n",
    "\n",
    "def model_init(model_name, num_labels, label2id, id2label):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=num_labels, label2id=label2id, id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Dataset class\n",
    "class Dialect_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        super(Dialect_dataset).__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return InputFeatures(self.X[\"input_ids\"][key], self.X[\"attention_mask\"][key], label=self.Y[key])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data (loading, preprocessing, tokenizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Date to dataframe (2.9 s)\n",
    "df = get_SMADC_folder_data()\n",
    "\n",
    "# Encode Y (307 ms)\n",
    "classes = df[\"Region\"].unique()\n",
    "num_labels = len(classes)\n",
    "class_to_index = {class_:index for class_, index in zip(classes, range(len(classes)))}\n",
    "index_to_class = {index:class_ for class_, index in zip(classes, range(len(classes)))}\n",
    "df[\"Labels\"] = df[\"Region\"].apply(class_to_index.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further preprocessing (If you want to load data, skip until loading section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Preprocess X (16min 22s)\n",
    "df[\"Text\"] = df[\"Text\"].apply(arabert_prep.preprocess)\n",
    "\n",
    "# split and (323ms)\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=1)\n",
    "validate, test = train_test_split(test, test_size=len(test)-validation_size, random_state=1)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "validate.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize everything at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validate_encoding = tokenize(validate[\"Text\"].to_list())\n",
    "test_encoding = tokenize(test[\"Text\"].to_list())\n",
    "train_encoding = tokenize(list(train[\"Text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# validate_encoding = batch_tokenize(validate[\"Text\"], 10)\n",
    "# test_encoding = batch_tokenize(test[\"Text\"], 100)\n",
    "# train_encoding = batch_tokenize(train[\"Text\"], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 746 ms\n"
     ]
    }
   ],
   "source": [
    "%%time    \n",
    "# Make Dataset \n",
    "validate_dataset = Dialect_dataset(validate_encoding, validate[\"Labels\"].to_list())\n",
    "test_dataset = Dialect_dataset(test_encoding, test[\"Labels\"].to_list())\n",
    "train_dataset = Dialect_dataset(train_encoding, train[\"Labels\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save_preprocessed_data(validate_dataset, \"preprocessed_validation\")\n",
    "# save_preprocessed_data(test_dataset, \"preprocessed_test\")\n",
    "# save_preprocessed_data(train_dataset, \"preprocessed_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# validate_dataset = load_preprocessed_data(\"preprocessed_validation\")\n",
    "# test_dataset = load_preprocessed_data(\"preprocessed_test\")\n",
    "# train_dataset = load_preprocessed_data(\"preprocessed_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 39612. Total steps: 198060\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(model_string)\n",
    "\n",
    "training_args.adam_epsilon = 1e-8\n",
    "training_args.learning_rate = 5e-5\n",
    "\n",
    "training_args.fp16 = True\n",
    "\n",
    "training_args.per_device_train_batch_size = 32\n",
    "training_args.per_device_eval_batch_size = 32\n",
    "\n",
    "training_args.gradient_accumulation_steps = 1\n",
    "\n",
    "training_args.num_train_epochs = 5\n",
    "\n",
    "steps_per_epoch = len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\n",
    "total_steps = steps_per_epoch * training_args.num_train_epochs\n",
    "print(f\"Steps per epoch: {steps_per_epoch}. Total steps: {total_steps}\")\n",
    "\n",
    "warmup_ratio = 0.05\n",
    "training_args.warmup_steps = total_steps * warmup_ratio \n",
    "\n",
    "training_args.logging_steps = 1024\n",
    "training_args.evaluation_strategy = EvaluationStrategy.STEPS\n",
    "# training_args.save_strategy = EvaluationStrategy.STEPS\n",
    "training_args.eval_strategy = EvaluationStrategy.STEPS\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.load_best_model_at_end = True\n",
    "training_args.eval_steps = 1024 # defaults to logging_steps\n",
    " \n",
    "# training_args.greater_is_better = False # Loss lower is better\n",
    "\n",
    "training_args.save_steps = 1024\n",
    "training_args.save_total_limit = 10\n",
    "\n",
    "training_args.seed = 1\n",
    "\n",
    "training_args.lr_scheduler_type = 'cosine'\n",
    "\n",
    "training_args.metric_for_best_model= \"eval_loss\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"EGY\",\n",
      "    \"1\": \"GLF\",\n",
      "    \"2\": \"IRQ\",\n",
      "    \"3\": \"LEV\",\n",
      "    \"4\": \"NOR\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"EGY\": 0,\n",
      "    \"GLF\": 1,\n",
      "    \"IRQ\": 2,\n",
      "    \"LEV\": 3,\n",
      "    \"NOR\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/pytorch_model.bin from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\da598d10a62ed68f0b95e0c032d813a008518ba8fe1d02fb191884f844c818ce.97462e17e0f13709a0a977021298c2733cda0cb6787facbeeb0b53199a7e73bf\n",
      "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are adding a <class 'transformers.integrations.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "EarlyStoppingCallback\n",
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=lambda:model_init(model_name, len(classes), label2id=class_to_index, id2label=index_to_class),\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validate_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3), TensorBoardCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/config.json from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\fcf7a61cc072840ad32e1a2e8eb230a79b33db68e3f965f8014a52915cab999f.2f0d0092105af7b8b42b899ffb7f801dc48e93516d509483f6cfbd86155d49ea\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"EGY\",\n",
      "    \"1\": \"GLF\",\n",
      "    \"2\": \"IRQ\",\n",
      "    \"3\": \"LEV\",\n",
      "    \"4\": \"NOR\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"EGY\": 0,\n",
      "    \"GLF\": 1,\n",
      "    \"IRQ\": 2,\n",
      "    \"LEV\": 3,\n",
      "    \"NOR\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv2/resolve/main/pytorch_model.bin from cache at C:\\Users\\mohnd/.cache\\huggingface\\transformers\\da598d10a62ed68f0b95e0c032d813a008518ba8fe1d02fb191884f844c818ce.97462e17e0f13709a0a977021298c2733cda0cb6787facbeeb0b53199a7e73bf\n",
      "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 1267610\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 198065\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='903' max='198065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   903/198065 03:54 < 14:16:27, 3.84 it/s, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class EvaluatePleaseCallback(transformers.TrainerCallback):\n",
    "    def on_save(self, args, state, control, model, **kwargs):\n",
    "        trainer.evaluate()\n",
    "\n",
    "trainer.add_callback(EvaluatePleaseCallback())\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(trainer.args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(trainer.state.log_history)\n",
    "history.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.plot(x=\"step\", y=\"loss\", backend=\"plotly\", title=\"Steps over loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[\"rounded_epoch\"] = round(history[\"epoch\"])\n",
    "history.plot(x=\"rounded_epoch\", y=\"loss\", backend=\"plotly\", title=\"Steps over loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(history, x=\"step\", y=\"loss\", title=\"Steps over loss\")\n",
    "# fig.add_trace(\n",
    "#     next(px.line(history, x=\"step\", y=\"\").select_traces())\n",
    "# )\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 7e-5, step=1e-5),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\",0,total_steps*0.1,step=total_steps*0.1*0.5),\n",
    "        \"gradient_accumulation_steps\" : trail.suggest_int(\"gradient_accumulation_steps\" , 1 , 10)\n",
    "    }\n",
    "\n",
    "search_space = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 7e-5, step=1e-5),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\",0,total_steps*0.1,step=total_steps*0.1*0.5),\n",
    "        \"gradient_accumulation_steps\" : trail.suggest_int(\"gradient_accumulation_steps\" , 1 , 10)\n",
    "}\n",
    "\n",
    "def compute_objective(metrics):\n",
    "    return metrics['eval_accuracy'] # or try \"accuracy\" if didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_model = trainer.hyperparameter_search(direction=\"maximize\",\n",
    "                                         hp_space=hp_space,\n",
    "                                         compute_objective=my_objective,\n",
    "                                         n_trials=None,\n",
    "                                         pruner=optuna.pruners.NopPruner(),\n",
    "                                         sampler=optuna.samplers.GridSampler(search_space),\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.hyperparameter_search(n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelWrapper(torch.nn.Module):\n",
    "#     def __init__(self, model: torch.nn.Module):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "\n",
    "#     def forward(self, input_x: torch.Tensor):\n",
    "#         data = self.model(input_x)\n",
    "\n",
    "#         if isinstance(data, dict):\n",
    "#             data_named_tuple = namedtuple(\"ModelEndpoints\", sorted(data.keys())) \n",
    "#             data = data_named_tuple(**data)\n",
    "\n",
    "#         elif isinstance(data, list):\n",
    "#             data = tuple(data)\n",
    "\n",
    "#         return data\n",
    "    \n",
    "# writer = SummaryWriter()\n",
    "# _, tensorboard = train_test_split(validate, test_size=100, random_state=1)\n",
    "# costume_data = validate_dataset.X[\"input_ids\"][:100].cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
